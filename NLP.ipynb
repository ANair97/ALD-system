{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e070a878-a9aa-40e2-96af-519a20f3b2e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7afcf16-270d-4e7c-b88d-dad9084fd719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting percentage of proper nouns matched \n",
    "def proper_noun_match_percentage(candidate_answer,model_answer):\n",
    "    #pos tagging both answers\n",
    "    candidate_answer_POS=nltk.pos_tag(candidate_answer)\n",
    "    model_answer_POS=nltk.pos_tag(model_answer)\n",
    "    \n",
    "    #function to get proper nouns from an answer\n",
    "    def getting_proper_noun(answer):\n",
    "        proper_nouns=[]\n",
    "        for word in answer:\n",
    "            if (word[1] == 'NNP' or word[1] == 'NNPS'):\n",
    "                proper_nouns.append(word[0])\n",
    "        return proper_nouns\n",
    "    \n",
    "    #calling above defined function to get proper nouns in both candidate and model answer\n",
    "    candidate_answer_proper_nouns = getting_proper_noun(candidate_answer_POS)\n",
    "    model_answer_proper_nouns = getting_proper_noun(model_answer_POS)\n",
    "    \n",
    "    #checking the number of proper nouns in model answer\n",
    "    proper_noun_count = len(model_answer_proper_nouns)\n",
    "    \n",
    "    #variable that will count the number of proper nouns that match\n",
    "    proper_noun_match_count = 0\n",
    "    \n",
    "    #finding the number of proper nouns that match\n",
    "    for word in candidate_answer_proper_nouns:\n",
    "        if word in model_answer_proper_nouns:\n",
    "            proper_noun_match_count += 1\n",
    "    \n",
    "    #calculating percentage of proper nouns that match.\n",
    "    if proper_noun_count != 0:\n",
    "        proper_noun_match_percentage = ( proper_noun_match_count / proper_noun_count) * 100\n",
    "    else:\n",
    "        proper_noun_match_percentage = 100  \n",
    "    return proper_noun_match_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd1ee84-6fbb-49a8-81f3-928350b5af92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wordnet\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#calculating percentage of words that match\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_match_percentage\u001b[39m(candidate_answer,model_answer):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "#calculating percentage of words that match\n",
    "def word_match_percentage(candidate_answer,model_answer):\n",
    "    unmatched_words=[]\n",
    "    matched_words_count=0\n",
    "    \n",
    "    #checks for words that macth and increase matched_words_count by 1. The words that don't match are inserted into unmatched_words list \n",
    "    for word in model_answer:\n",
    "        if word in candidate_answer:\n",
    "            matched_words_count += 1\n",
    "        else:\n",
    "            unmatched_words.append(word)\n",
    "\n",
    "    #find synonyms for unmatched words\n",
    "    unmatched_words_synonyms = []\n",
    "    for word in unmatched_words:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                unmatched_words_synonyms.append(l.name())\n",
    "    \n",
    "    #checking if the synonyms of unmatched words match with words in candidate answer, and if it does increase matched_words_count\n",
    "    for word in candidate_answer:\n",
    "        if word in unmatched_words_synonyms:\n",
    "            matched_words_count += 1\n",
    "            \n",
    "    #finding the precentage of similair words in candidate answer compared to model answer        \n",
    "    model_answer_length = len(model_answer)\n",
    "    word_match_percentage = ( matched_words_count / model_answer_length) * 100\n",
    "    \n",
    "    return word_match_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be26dff-1188-42a2-a813-d863e722f6fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bigrams\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Bigram similarity\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbigram_similarity_percentage\u001b[39m(candidate_answer,model_answer):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.util import bigrams\n",
    "#Bigram similarity\n",
    "def bigram_similarity_percentage(candidate_answer,model_answer):\n",
    "    candidate_answer_bigram_tokenized = []\n",
    "    model_answer_bigram_tokenized = []\n",
    "    \n",
    "    #getting bigrams of both model and candidate answer\n",
    "    candidate_bigram = bigrams(candidate_answer)\n",
    "    model_bigram = bigrams(model_answer)\n",
    "    \n",
    "    for w in candidate_bigram:\n",
    "        candidate_answer_bigram_tokenized.append(w)\n",
    "        \n",
    "    for w in model_bigram:\n",
    "        model_answer_bigram_tokenized.append(w)\n",
    "\n",
    "    \n",
    "    #checking the number of bigrams in model answer\n",
    "    bigrams_count = len(model_answer_bigram_tokenized)\n",
    "    \n",
    "    #variable that will count the number of bigrams that are present in both answers\n",
    "    bigram_similarity_count = 0\n",
    "    \n",
    "    #finding the number of bigrams that match\n",
    "    for bigram in candidate_answer_bigram_tokenized:\n",
    "        if bigram in model_answer_bigram_tokenized:\n",
    "            bigram_similarity_count += 1\n",
    "    \n",
    "    #calculating percentage of bigrams that match\n",
    "    bigram_similarity_percentage = ( bigram_similarity_count / bigrams_count) * 100\n",
    "    \n",
    "    return bigram_similarity_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c6bc6b-f564-451c-9a48-8bbc5fa18e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(candidate_answer,model_answer):\n",
    "\n",
    "    # form a list containing keywords of both strings. Basically union of candidate_answer and model_answer  \n",
    "    keywords_union = list(set(candidate_answer) | set(model_answer))\n",
    "    A =[];B =[] \n",
    "    for w in keywords_union: \n",
    "        if w in candidate_answer: A.append(1) # create a vector \n",
    "        else: A.append(0) \n",
    "        if w in model_answer: B.append(1) \n",
    "        else: B.append(0) \n",
    "    c = 0\n",
    "\n",
    "    # cosine formula  \n",
    "    for i in range(len(keywords_union)): \n",
    "            c+= A[i]*B[i] \n",
    "    cosine = c / float((sum(A)*sum(B))**0.5) \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71b7858-7619-42c0-b874-e9e641500015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(candidate_answer,model_answer):\n",
    "    \n",
    "    #getting intersection of candidate_answer and model_answer\n",
    "    keywords_intersection = list(set(candidate_answer) & set(model_answer)) \n",
    "    \n",
    "    #form a list containing keywords of both strings. Basically union of candidate_answer and model_answer  \n",
    "    keywords_union = list(set(candidate_answer) | set(model_answer))\n",
    "    \n",
    "    return (len(keywords_intersection) / len(keywords_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dadd8cbf-2d84-4627-8c4f-67cf85f8771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_similarity(candidate_answer,model_answer):\n",
    "    \n",
    "    #getting intersection of candidate_answer and model_answer\n",
    "    keywords_intersection = list(set(candidate_answer) & set(model_answer))\n",
    "    \n",
    "    return ((2 * len(keywords_intersection)) / (len(candidate_answer) + len(model_answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbc1ef-0a61-4c5e-8302-229d2c40c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preparation of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3694e37-6a5a-484f-a103-3d01649c0f93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msr\u001b[39;00m\n\u001b[1;32m      3\u001b[0m r \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mMicrophone() \u001b[38;5;28;01mas\u001b[39;00m source:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Give your answer!\")\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "try:\n",
    "    original_candidate_answer = r.recognize_google(audio) \n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "694c1414-8fe4-481b-aaa5-f15a9803b278",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_candidate_answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m original_model_answer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHertfordshire is one of the home counties in southern England. It is bordered by Bedfordshire and Cambridgeshire to the north, Essex to the east, Greater London to the south, and Buckinghamshire to the west\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43moriginal_candidate_answer\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_candidate_answer' is not defined"
     ]
    }
   ],
   "source": [
    "original_model_answer=\"Hertfordshire is one of the home counties in southern England. It is bordered by Bedfordshire and Cambridgeshire to the north, Essex to the east, Greater London to the south, and Buckinghamshire to the west\"\n",
    "original_candidate_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a733a0-ecec-48be-99ed-3ff0d18ab2e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m      2\u001b[0m stop_words\u001b[38;5;241m=\u001b[39mstopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926713fa-5ea8-4ea6-b84a-2498f0b72356",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      3\u001b[0m model_answer_tokenized \u001b[38;5;241m=\u001b[39m word_tokenize(original_model_answer)\n\u001b[1;32m      4\u001b[0m candidate_answer_tokenized \u001b[38;5;241m=\u001b[39m word_tokenize(original_candidate_answer)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "model_answer_tokenized = word_tokenize(original_model_answer)\n",
    "candidate_answer_tokenized = word_tokenize(original_candidate_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3933a538-3251-45b6-8c49-cece1d424828",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidate_answer_tokenized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenized candidate answer ->\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mcandidate_answer_tokenized\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenized model answer ->\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_answer_tokenized)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'candidate_answer_tokenized' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized candidate answer ->\", candidate_answer_tokenized)\n",
    "print(\"Tokenized model answer ->\", model_answer_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "133d5c06-f49c-4f19-91a2-c037c903c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words from model and candiadte answer\n",
    "def removing_stopwords(tokenized_answer):\n",
    "    filtered_sentence=[]\n",
    "    for word in tokenized_answer:\n",
    "         if word not in stop_words:\n",
    "                filtered_sentence.append(word)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eabd7d0-1ad4-4363-a9f2-c1e399745540",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_answer_tokenized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_answer\u001b[38;5;241m=\u001b[39mremoving_stopwords(\u001b[43mmodel_answer_tokenized\u001b[49m)\n\u001b[1;32m      2\u001b[0m candidate_answer\u001b[38;5;241m=\u001b[39mremoving_stopwords(candidate_answer_tokenized)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate answer without stopwords ->\u001b[39m\u001b[38;5;124m\"\u001b[39m, candidate_answer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_answer_tokenized' is not defined"
     ]
    }
   ],
   "source": [
    "model_answer=removing_stopwords(model_answer_tokenized)\n",
    "candidate_answer=removing_stopwords(candidate_answer_tokenized)\n",
    "print(\"Candidate answer without stopwords ->\", candidate_answer)\n",
    "print(\"Model answer without stopwords ->\", model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ae3dd-511c-418a-8496-be2b8602e61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Calling functions to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "583d446d-16bc-4646-98a6-505b26e3c3fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidate_answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m proper_noun_match \u001b[38;5;241m=\u001b[39m proper_noun_match_percentage(\u001b[43mcandidate_answer\u001b[49m,model_answer)\n\u001b[1;32m      2\u001b[0m word_match \u001b[38;5;241m=\u001b[39m word_match_percentage(candidate_answer,model_answer)\n\u001b[1;32m      3\u001b[0m bigram_match \u001b[38;5;241m=\u001b[39m bigram_similarity_percentage(candidate_answer,model_answer) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'candidate_answer' is not defined"
     ]
    }
   ],
   "source": [
    "proper_noun_match = proper_noun_match_percentage(candidate_answer,model_answer)\n",
    "word_match = word_match_percentage(candidate_answer,model_answer)\n",
    "bigram_match = bigram_similarity_percentage(candidate_answer,model_answer) \n",
    "cosine = cosine_similarity(candidate_answer,model_answer)\n",
    "jaccard = jaccard_similarity(candidate_answer,model_answer) \n",
    "dice = dice_similarity(candidate_answer,model_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9c92eaf-35ed-453d-a949-bc835a2b8ae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proper_noun_match' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mproper_noun_match\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proper_noun_match' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "proper_noun_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "376d3f91-fb78-4e39-9890-a4f7bfa6cd91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_match' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mword_match\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_match' is not defined"
     ]
    }
   ],
   "source": [
    "word_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f4f943e-0f72-4999-90db-ea608948969c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bigram_match' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbigram_match\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bigram_match' is not defined"
     ]
    }
   ],
   "source": [
    "bigram_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86980981-ac3b-4691-8183-6bea50b3390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
